# EL Amraoui Abir ENCG SETTAT Finance G2                    
# Apog√©: 24010353
![Abir](https://github.com/elamraouiabir6963encg-rgb/24010353_ELAMRAOUI-ABIR/blob/main/Image/Abir.png?raw=true)

# üè¶ Analyse Exploratoire et Mod√©lisation Pr√©dictive  
## Dataset Bank Marketing (UCI)

---

## 1. Probl√©matique, m√©tier et objectifs de la mission

### Probl√©matique du m√©tier
Dans le secteur bancaire, les campagnes de t√©l√©-marketing constituent un levier strat√©gique pour promouvoir les d√©p√¥ts √† terme, un produit d‚Äô√©pargne essentiel pour assurer la liquidit√© et la stabilit√© financi√®re des banques.
Cependant, ces campagnes pr√©sentent plusieurs limites op√©rationnelles et financi√®res :
    *   Co√ªts √©lev√©s li√©s aux centres d‚Äôappels.
    *   Taux de conversion faible, car la majorit√© des clients contact√©s ne souscrivent pas au produit.
    *   Ciblage inefficace, entra√Ænant une surcharge des agents et une allocation non optimale du budget marketing. 
    *   Perte d‚Äôopportunit√©s commerciales,  lorsque des clients potentiellement int√©ress√©s ne sont pas identifi√©s √† temps.
Ainsi, la banque se trouve confront√©e √† un d√©fi majeur :
*   **Comment identifier, avant m√™me l‚Äôappel, les clients ayant la plus forte probabilit√© de souscrire √† un d√©p√¥t √† terme, afin d‚Äôoptimiser les ressources et maximiser le rendement des campagnes ?** 

### L‚ÄôEnjeu d√©cisionnel : Une mlatrice de co√ªts d‚Äôerreur asym√©trique
Contrairement √† des probl√©matiques classiques de classification, ici toutes les erreurs n‚Äôont pas le m√™me impact :
    *   Faux Positif: un client est pr√©dit comme int√©ress√© alors qu‚Äôil ne souscrira pas                                                          ‚Üí Co√ªt op√©rationnel inutile, perte de temps agent, saturation des lignes d‚Äôappels.
    *   Faux N√©gatif: un client r√©ellement int√©ress√© est class√© comme non pertinent                                                              ‚Üí Manque √† gagner commercial direct, perte potentielle de valeur client √† long terme. 
        ‚û§  Co√ªt op√©rationnel inutile, perte de temps agent, saturation des lignes d‚Äôappels
Faux N√©gatif (FN) : un client r√©ellement int√©ress√© est class√© comme non pertinent 
         ‚û§  Manque √† gagner commercial direct, perte potentielle de valeur client √† long terme

Dans ce contexte, la priorit√© strat√©gique n‚Äôest pas seulement la pr√©cision, mais surtout :
**Maximiser le rappel de la classe positive, afin de r√©duire au maximum les faux n√©gatifs et ne pas laisser passer les clients int√©ress√©s.**

### L‚ÄôEnjeu d√©cisionnel : Une mlatrice de co√ªts d‚Äôerreur asym√©trique
La mission consiste donc √† concevoir un Assistant IA d‚Äôaide au ciblage client, bas√© sur le machine learning, permettant de :
    *   Analyser le comportement et le profil client.
    *   Pr√©dire la probabilit√© de souscription avant le contact t√©l√©phonique.
    *   Optimiser le ciblage des campagnes marketing. 
    *   R√©duire les co√ªts op√©rationnels li√©s aux appels non pertinents.
    *   Augmenter le taux de conversion et le rendement global des campagnes.
    *   Fournir un outil scalable pouvant √™tre int√©gr√© dans un syst√®me CRM bancaire.

### Les Donn√©es utilis√©es (L‚ÄôInput du Mod√®le)
Pour r√©pondre √† cette mission, nous exploitons le dataset *Bank Marketing (UCI)*, qui contient des donn√©es historiques issues de campagnes r√©elles :
*   Profil socio-d√©mographique : √¢ge, profession, niveau d‚Äô√©ducation, situation familiale‚Ä¶
*   Indicateurs financiers : solde bancaire (balance)
*   Historique marketing : nombre de contacts lors de la campagne (campaign), r√©sultat des campagnes pr√©c√©dentes (poutcome), nombre de contacts ant√©rieurs (previous), d√©lai depuis le dernier contact (pdays)‚Ä¶
*   Variable cible (y) : souscription au d√©p√¥t √† terme ‚Üí yes ou no
*   Taille et format : 45 211 observations, 17 variables, donn√©es tabulaires, m√©langeant variables num√©riques et cat√©gorielles
Ces donn√©es permettent au mod√®le d‚Äôapprendre √† partir de tendances comportementales r√©elles, tout en tenant compte des contraintes √©conomiques du m√©tier.
---

## 2. Le Code Python simplifi√©

```python
# INSTALLATION & IMPORTS
# pip install ucimlrepo seaborn matplotlib pandas numpy

from ucimlrepo import fetch_ucirepo
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ============================================================
# 1) CHARGEMENT DES DONN√âES
# ============================================================
bank_marketing = fetch_ucirepo(id=222)
X = bank_marketing.data.features
y = bank_marketing.data.targets

df = pd.concat([X, y], axis=1)


# ============================================================
# 2) ANALYSE DES VARIABLES NUMERIQUES
# ============================================================
num_cols = df.select_dtypes(include=['int64', 'float64']).columns

# HISTOGRAMMES
for col in num_cols:
    sns.histplot(df[col], kde=True)
    plt.title(f"Distribution de {col}")
    plt.show()

# BOXPLOTS
for col in num_cols:
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot de {col}")
    plt.show()

# HEATMAP
plt.figure(figsize=(10,6))
corr = df[num_cols].corr()
sns.heatmap(corr, annot=True, cmap="coolwarm")
plt.title("Matrice de corr√©lation")
plt.show()

# ============================================================
# 3) FEATURE ENGINEERING
# ============================================================
df['age_group'] = pd.cut(df['age'], bins=[0,30,45,60,100],
                          labels=['Jeune', 'Adulte', 'Senior', 'Tr√®s senior'])
df['duration_min'] = df['duration'] / 60
df['total_contacts'] = df['campaign'] + df['previous']


# ============================================================
# 4) MODELISATION : LOGISTIC REGRESSION + RANDOM FOREST
# ============================================================
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

df['y'] = df['y'].map({'yes':1, 'no':0})

X = df.drop(columns=['y'])
y = df['y']

num_cols = X.select_dtypes(include=['int64','float64']).columns
cat_cols = X.select_dtypes(include=['object','category']).columns

preprocess = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ],
    remainder='passthrough'
)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

# ============================================================
# MODELE 1 : R√âGRESSION LOGISTIQUE
# ============================================================
log_reg_model = Pipeline(steps=[
    ('prep', preprocess),
    ('model', LogisticRegression(max_iter=1000))
])

log_reg_model.fit(X_train, y_train)
y_pred_log = log_reg_model.predict(X_test)



# ============================================================
# MODELE 2 : RANDOM FOREST
# ============================================================
rf_model = Pipeline(steps=[
    ('prep', preprocess),
    ('model', RandomForestClassifier(n_estimators=300, random_state=42))
])

rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

```
---

# 5. R√âSULTATS DE L'ANALYSE EXPLORATOIRE (EDA)

---

## 5.1 Aper√ßu des donn√©es
![Aper√ßu des donn√©es](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Aper%C3%A7u%20des%20donn%C3%A9es.png?raw=true)

## 5.2 Statistiques descriptives
![Statistiques descreptives](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Statistiques%20descreptives.png?raw=true)
üìå
Forte pr√©sence de valeurs extr√™mes ‚Üí besoin de prudence en mod√©lisation.

---

# 5.3 Histogrammes ‚Äì Distributions

### Age
![Distrtibution de Age](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20Age.png?raw=true)

üìå Interpr√©tation - age :
- La distribution permet d‚Äôobserver la forme g√©n√©rale (sym√©trique, asym√©trique, extr√™mes).
- Une asym√©trie indique une concentration des valeurs vers une borne.
- La pr√©sence de pics sugg√®re des groupes de clients distincts.


### Balance
![Distribbution de Balance](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20Balance.png?raw=true)
üìå Interpr√©tation - balance :
- La distribution permet d‚Äôobserver la forme g√©n√©rale (sym√©trique, asym√©trique, extr√™mes).
- Une asym√©trie indique une concentration des valeurs vers une borne.
- La pr√©sence de pics sugg√®re des groupes de clients distincts.

### Day of week
![Distribbution de pdays_of_week](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20day_of_week.png?raw=true)

üìå Interpr√©tation - day_of_week :
- La distribution permet d‚Äôobserver la forme g√©n√©rale (sym√©trique, asym√©trique, extr√™mes).
- Une asym√©trie indique une concentration des valeurs vers une borne.
- La pr√©sence de pics sugg√®re des groupes de clients distincts.

### Duration
![Distribbution de duration](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20duration.png?raw=true)

üìå Interpr√©tation - duration :
- La distribution permet d‚Äôobserver la forme g√©n√©rale (sym√©trique, asym√©trique, extr√™mes).
- Une asym√©trie indique une concentration des valeurs vers une borne.
- La pr√©sence de pics sugg√®re des groupes de clients distincts.

### Campaign
![Distribbution de campaign](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20campaign.png?raw=true)

üìå Interpr√©tation - campaign :
- La distribution permet d‚Äôobserver la forme g√©n√©rale (sym√©trique, asym√©trique, extr√™mes).
- Une asym√©trie indique une concentration des valeurs vers une borne.
- La pr√©sence de pics sugg√®re des groupes de clients distincts.

### Pdays
![Distribbution de pdays](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20pdays.png?raw=true)

üìå Interpr√©tation - pdays :
- La distribution permet d‚Äôobserver la forme g√©n√©rale (sym√©trique, asym√©trique, extr√™mes).
- Une asym√©trie indique une concentration des valeurs vers une borne.
- La pr√©sence de pics sugg√®re des groupes de clients distincts.

### Previous
![Distribbution de previous](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20previous.png?raw=true)

üìå Interpr√©tation - previous :
- La distribution permet d‚Äôobserver la forme g√©n√©rale (sym√©trique, asym√©trique, extr√™mes).
- Une asym√©trie indique une concentration des valeurs vers une borne.
- La pr√©sence de pics sugg√®re des groupes de clients distincts.

---

# 5.4 BOXPLOTS 

### Age
![Boxplot de age](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20age.png?raw=true)

üìå Interpr√©tation - age :
- Les points isol√©s repr√©sentent des valeurs aberrantes (outliers).
- Une bo√Æte large indique une forte dispersion.
- Une asym√©trie de la bo√Æte sugg√®re une distribution biais√©e.

### Balance
![Boxplot de Balance](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20Balance.png?raw=true)
üìå Interpr√©tation - balance :
- Les points isol√©s repr√©sentent des valeurs aberrantes (outliers).
- Une bo√Æte large indique une forte dispersion.
- Une asym√©trie de la bo√Æte sugg√®re une distribution biais√©e.

### Day of week
![Boxplot de day_of_week](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20day%20of%20week.png?raw=true)

üìå Interpr√©tation - day_of_week :
- Les points isol√©s repr√©sentent des valeurs aberrantes (outliers).
- Une bo√Æte large indique une forte dispersion.
- Une asym√©trie de la bo√Æte sugg√®re une distribution biais√©e.

### Duration
![Boxplot de duration](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20duration.png?raw=true)

üìå Interpr√©tation - duration :
- Les points isol√©s repr√©sentent des valeurs aberrantes (outliers).
- Une bo√Æte large indique une forte dispersion.
- Une asym√©trie de la bo√Æte sugg√®re une distribution biais√©e.

### Campaign
![Boxplot de campaign](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20campaign.png?raw=true)

üìå Interpr√©tation - campaign :
- Les points isol√©s repr√©sentent des valeurs aberrantes (outliers).
- Une bo√Æte large indique une forte dispersion.
- Une asym√©trie de la bo√Æte sugg√®re une distribution biais√©e.

### Pdays
![Boxplot de pdays](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20pdays.png?raw=true)

üìå Interpr√©tation - pdays :
- Les points isol√©s repr√©sentent des valeurs aberrantes (outliers).
- Une bo√Æte large indique une forte dispersion.
- Une asym√©trie de la bo√Æte sugg√®re une distribution biais√©e.

### Previous
![Boxplot de previous](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20previous.png?raw=true)

üìå Interpr√©tation - previous :
- Les points isol√©s repr√©sentent des valeurs aberrantes (outliers).
- Une bo√Æte large indique une forte dispersion.
- Une asym√©trie de la bo√Æte sugg√®re une distribution biais√©e.

# 5.5 HEATMAP ‚Äì Corr√©lations
![Matrice de corr√©lation](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Matrice%20de%20corr%C3%A9lation.png?raw=true)

üìå Interpr√©tation globale des corr√©lations :
- Une corr√©lation proche de 1 ou -1 indique une relation forte.
- Une valeur proche de 0 indique une ind√©pendance.
- Les relations fortes peuvent indiquer une redondance de variables.
- Utile pour la s√©lection des variables dans les mod√®les pr√©dictifs.

--- FEATURE ENGINEERING ---
‚úÖ Nouvelles variables cr√©√©es :
  age_group  duration_min  total_contacts
0    Senior      4.350000               1
1    Adulte      2.516667               1
2    Adulte      1.266667               1
3    Senior      1.533333               1
4    Adulte      3.300000               1

üìå Interpr√©tation des nouvelles variables :
- age_group : segmentation client plus claire.
- duration_min : plus interpr√©table que les secondes.
- total_contacts : estimation de la pression commerciale sur le client.

### R√©partition par √¢ge
![R√©partition par groupe d'√¢ge](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/R%C3%A9partition%20par%20groupe%20d'%C3%A2ge.png?raw=true)

üìå Interpr√©tation : Les adultes dominent le portefeuille clients.

### Dur√©e (minutes)
![Distribution de la dur√©e de contact](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20la%20dur%C3%A9e%20de%20contact.png?raw=true)

üìå Interpr√©tation : Les appels courts dominent ‚Äî peu d‚Äôappels longs tr√®s influents.

### Total contacts
![Distribution du nobre total de contacts](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20du%20nombre%20total%20de%20contacts.png?raw=true)

üìå Interpr√©tation : La majorit√© des clients est contact√©e peu de fois, signe de ciblage s√©lectif.

# 6. R√©sultats de la r√©gression logisqtique et random forest

# 6.1 R√©gression logistique
![R√©ression logisitique](https://github.com/elamraouiabir6963encg-rgb/24010353_ELAMRAOUI-ABIR/blob/main/Image/R%C3%A9gression%20logistique.png?raw=true)

üìå Interpr√©tation :  
* La r√©gression logistique fournit une base simple pour pr√©dire l'abonnement.
* Si le recall sur la classe 1 (yes) est faible, le mod√®le a du mal √† d√©tecter les clients positifs.
* Une bonne pr√©cision signifie peu de faux positifs.
* Ce mod√®le est lin√©aire : il peut sous-performer si les relations ne sont pas lin√©aires.

# 6.2 Random forest
![Random forest](https://github.com/elamraouiabir6963encg-rgb/24010353_ELAMRAOUI-ABIR/blob/main/Image/Random%20forest.png?raw=true)

üìå Interpr√©tation :
* Ce mod√®le est souvent plus performant car il capture les non-lin√©arit√©s.
* Il r√©duit le surapprentissage gr√¢ce √† l‚Äôagr√©gation de nombreux arbres.
* Si le recall et la pr√©cision sont sup√©rieurs √† ceux de la r√©gression logistique, le mod√®le est meilleur.
* Random Forest est g√©n√©ralement le meilleur choix sur Bank Marketing.

---

# 7. INTERPR√âTATION G√âN√âRALE

| Point               | Conclusion             |
| ------------------- | ---------------------- |
| Dataset             | fiable                 |
| Outliers            | nombreux               |
| Corr√©lation         | faible sauf `duration` |
| Feature engineering | pertinent              |
| Probl√®me potentiel  | fuite de donn√©es       |

---

# 8. CONCLUSION
* L‚ÄôEDA r√©v√®le la distribution, la pr√©sence potentielle d‚Äôoutliers et les relations entre variables.
* Le feature engineering enrichit les donn√©es pour am√©liorer les mod√®les.
* La r√©gression logistique sert de mod√®le de base lin√©aire.
* Le Random Forest capture des relations plus complexes et donne souvent de meilleurs r√©sultats.
* La comparaison des m√©triques permet de choisir le meilleur mod√®le pour la pr√©diction de l'abonnement.
---

## Pistes d‚Äôam√©lioration

* Imputation intelligente
* Encodage cat√©goriel
* Standardisation
* S√©lection de variables
* Validation crois√©e
* Mod√©lisation ML (Logistic, Random Forest, XGBoost)

---

‚úÖ **Analyse exploratoire finalis√©e avec succ√®s.**

