# EL Amraoui Abir ENCG SETTAT Finance G2
# ApogÃ©: 24010353
![Abir](https://github.com/user-attachments/assets/19b86bed-ac87-4f8e-938c-862cf3722380)

# ğŸ¦ Analyse Exploratoire et ModÃ©lisation PrÃ©dictive  
## Dataset Bank Marketing (UCI)

---

## 1. Le Contexte MÃ©tier et la Mission

### Le ProblÃ¨me (Business Case)
Les banques utilisent des campagnes de tÃ©lÃ©â€‘marketing pour convaincre les clients de souscrire Ã  un dÃ©pÃ´t Ã  terme. Or :
    *   Ces campagnes coÃ»tent cher,
    *   La majoritÃ© des clients ne rÃ©pondent pas favorablement,
    *   Un mauvais ciblage = perte dâ€™argent + surcharge des centres dâ€™appels. 
*   **Objectif :** CrÃ©er un "Assistant IA" pour prÃ©dire quels clients sont susceptibles de souscrire afin d'optimiser les campagnes.
*   **L'Enjeu critique :** La matrice des coÃ»ts d'erreur est asymÃ©trique.
    *   Faux Positif: On appelle un client qui ne sera jamais intÃ©ressÃ© â†’ perte de temps et coÃ»t opÃ©rationnel.
    *   Faux NÃ©gatif: on rate un client rÃ©ellement intÃ©ressÃ© â†’ manque Ã  gagner commercial. **L'IA doit donc maximiser le rappel pour ne pas manquer des clients intÃ©ressÃ©s.**

### Les DonnÃ©es (L'Input)
On utilise le *Bank Marketing (UCI)*.
*   Profil client : Ã¢ge, mÃ©tier, Ã©ducationâ€¦
*   Situation financiÃ¨re : solde bancaire
*   Historique marketing : nombre de contacts, rÃ©sultat des anciennes campagnesâ€¦
*   cible : y = oui/non (a souscrit ou non)
*   Format : 45 211 observations, 17 colonnes.
---
## 2. Le Code Python 

```python
from ucimlrepo import fetch_ucirepo
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

bank_marketing = fetch_ucirepo(id=222)
X = bank_marketing.data.features
y = bank_marketing.data.targets

df = pd.concat([X, y], axis=1)

print(df.head())
print(df.info())
print(df.describe())

num_cols = df.select_dtypes(include=['int64', 'float64']).columns

# HISTOGRAMMES
for col in num_cols:
    sns.histplot(df[col], kde=True)
    plt.title(f"Distribution de {col}")
    plt.show()

# BOXPLOTS
for col in num_cols:
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot de {col}")
    plt.show()

# HEATMAP
plt.figure(figsize=(10,6))
corr = df[num_cols].corr()
sns.heatmap(corr, annot=True, cmap="coolwarm")
plt.title("Matrice de corrÃ©lation")
plt.show()

# FEATURE ENGINEERING
df['age_group'] = pd.cut(df['age'], bins=[0,30,45,60,100],
                          labels=['Jeune', 'Adulte', 'Senior', 'TrÃ¨s senior'])
df['duration_min'] = df['duration'] / 60
df['total_contacts'] = df['campaign'] + df['previous']
````
## 3. Analyse Approfondie : Nettoyage 

### Le ProblÃ¨me des donnÃ©es bruts
Le dataset comporte :
    *   Des valeurs manquantes (job, education, contact, poutcome),
    *   Des valeurs extrÃªmes (ex : balance, duration, previous),
    *   Des distributions fortement asymÃ©triques. 
Ces problÃ¨mes perturbent les modÃ¨les de Machine Learning car :
    *   Les distributions biaisÃ©es trompent les algorithmes,
    *   Les outliers influencent les dÃ©cisions,
    *   Les valeurs manquantes empÃªchent certains algorithmes de sâ€™exÃ©cuter. 
### La fuite des donnÃ©es
Le modÃ¨le final devra toujours Ã©viter :
*   Calcul de moyennes sur lâ€™ensemble du dataset,
*   Transformation avant sÃ©paration Train/Test.
Ici, lâ€™objectif Ã©tant lâ€™EDA, la prioritÃ© est lâ€™analyse, pas la performance.
---
# 4. Justification des choix
*   **Visualisation :** 
    *   AsymÃ©tries
    *   Valeurs aberrantes (outliers)
    *   Groupes de population
*   **CorrÃ©lation :** La heatmap identifie les redondances et relations significatives.
*   **Feature Engineering :** Objectifs.
    *   AmÃ©liorer lâ€™interprÃ©tabilitÃ©
    *   CrÃ©er des variables explicatives plus pertinentes

---

# 5. RÃ‰SULTATS DE L'ANALYSE EXPLORATOIRE (EDA)

---

## 5.1 AperÃ§u des donnÃ©es
![AperÃ§u des donnÃ©es](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Aper%C3%A7u%20des%20donn%C3%A9es.png?raw=true)

## 5.2 Statistiques descriptives
![Statistiques descreptives](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Statistiques%20descreptives.png?raw=true)
ğŸ“Œ
Forte prÃ©sence de valeurs extrÃªmes â†’ besoin de prudence en modÃ©lisation.

---

# 5.3 Histogrammes â€“ Distributions

### Age
![Distrtibution de Age](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20Age.png?raw=true)

ğŸ“Œ InterprÃ©tation - age :
- La distribution permet dâ€™observer la forme gÃ©nÃ©rale (symÃ©trique, asymÃ©trique, extrÃªmes).
- Une asymÃ©trie indique une concentration des valeurs vers une borne.
- La prÃ©sence de pics suggÃ¨re des groupes de clients distincts.


### Balance
![Distribbution de Balance](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20Balance.png?raw=true)
ğŸ“Œ InterprÃ©tation - balance :
- La distribution permet dâ€™observer la forme gÃ©nÃ©rale (symÃ©trique, asymÃ©trique, extrÃªmes).
- Une asymÃ©trie indique une concentration des valeurs vers une borne.
- La prÃ©sence de pics suggÃ¨re des groupes de clients distincts.

### Day of week
![Distribbution de pdays_of_week](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20day_of_week.png?raw=true)

ğŸ“Œ InterprÃ©tation - day_of_week :
- La distribution permet dâ€™observer la forme gÃ©nÃ©rale (symÃ©trique, asymÃ©trique, extrÃªmes).
- Une asymÃ©trie indique une concentration des valeurs vers une borne.
- La prÃ©sence de pics suggÃ¨re des groupes de clients distincts.

### Duration
![Distribbution de duration](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20duration.png?raw=true)

ğŸ“Œ InterprÃ©tation - duration :
- La distribution permet dâ€™observer la forme gÃ©nÃ©rale (symÃ©trique, asymÃ©trique, extrÃªmes).
- Une asymÃ©trie indique une concentration des valeurs vers une borne.
- La prÃ©sence de pics suggÃ¨re des groupes de clients distincts.

### Campaign
![Distribbution de campaign](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20campaign.png?raw=true)

ğŸ“Œ InterprÃ©tation - campaign :
- La distribution permet dâ€™observer la forme gÃ©nÃ©rale (symÃ©trique, asymÃ©trique, extrÃªmes).
- Une asymÃ©trie indique une concentration des valeurs vers une borne.
- La prÃ©sence de pics suggÃ¨re des groupes de clients distincts.

### Pdays
![Distribbution de pdays](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20pdays.png?raw=true)

ğŸ“Œ InterprÃ©tation - pdays :
- La distribution permet dâ€™observer la forme gÃ©nÃ©rale (symÃ©trique, asymÃ©trique, extrÃªmes).
- Une asymÃ©trie indique une concentration des valeurs vers une borne.
- La prÃ©sence de pics suggÃ¨re des groupes de clients distincts.

### Previous
![Distribbution de previous](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20previous.png?raw=true)

ğŸ“Œ InterprÃ©tation - previous :
- La distribution permet dâ€™observer la forme gÃ©nÃ©rale (symÃ©trique, asymÃ©trique, extrÃªmes).
- Une asymÃ©trie indique une concentration des valeurs vers une borne.
- La prÃ©sence de pics suggÃ¨re des groupes de clients distincts.

---

# 5.4 BOXPLOTS 

### Age
![Boxplot de age](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20age.png?raw=true)

ğŸ“Œ InterprÃ©tation - age :
- Les points isolÃ©s reprÃ©sentent des valeurs aberrantes (outliers).
- Une boÃ®te large indique une forte dispersion.
- Une asymÃ©trie de la boÃ®te suggÃ¨re une distribution biaisÃ©e.

### Balance
![Boxplot de Balance](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20Balance.png?raw=true)
ğŸ“Œ InterprÃ©tation - balance :
- Les points isolÃ©s reprÃ©sentent des valeurs aberrantes (outliers).
- Une boÃ®te large indique une forte dispersion.
- Une asymÃ©trie de la boÃ®te suggÃ¨re une distribution biaisÃ©e.

### Day of week
![Boxplot de day_of_week](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20day%20of%20week.png?raw=true)

ğŸ“Œ InterprÃ©tation - day_of_week :
- Les points isolÃ©s reprÃ©sentent des valeurs aberrantes (outliers).
- Une boÃ®te large indique une forte dispersion.
- Une asymÃ©trie de la boÃ®te suggÃ¨re une distribution biaisÃ©e.

### Duration
![Boxplot de duration](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20duration.png?raw=true)

ğŸ“Œ InterprÃ©tation - duration :
- Les points isolÃ©s reprÃ©sentent des valeurs aberrantes (outliers).
- Une boÃ®te large indique une forte dispersion.
- Une asymÃ©trie de la boÃ®te suggÃ¨re une distribution biaisÃ©e.

### Campaign
![Boxplot de campaign](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20campaign.png?raw=true)

ğŸ“Œ InterprÃ©tation - campaign :
- Les points isolÃ©s reprÃ©sentent des valeurs aberrantes (outliers).
- Une boÃ®te large indique une forte dispersion.
- Une asymÃ©trie de la boÃ®te suggÃ¨re une distribution biaisÃ©e.

### Pdays
![Boxplot de pdays](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20pdays.png?raw=true)

ğŸ“Œ InterprÃ©tation - pdays :
- Les points isolÃ©s reprÃ©sentent des valeurs aberrantes (outliers).
- Une boÃ®te large indique une forte dispersion.
- Une asymÃ©trie de la boÃ®te suggÃ¨re une distribution biaisÃ©e.

### Previous
![Boxplot de previous](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Boxplot%20de%20previous.png?raw=true)

ğŸ“Œ InterprÃ©tation - previous :
- Les points isolÃ©s reprÃ©sentent des valeurs aberrantes (outliers).
- Une boÃ®te large indique une forte dispersion.
- Une asymÃ©trie de la boÃ®te suggÃ¨re une distribution biaisÃ©e.

# 5.5 HEATMAP â€“ CorrÃ©lations
![Matrice de corrÃ©lation](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Matrice%20de%20corr%C3%A9lation.png?raw=true)

ğŸ“Œ InterprÃ©tation globale des corrÃ©lations :
- Une corrÃ©lation proche de 1 ou -1 indique une relation forte.
- Une valeur proche de 0 indique une indÃ©pendance.
- Les relations fortes peuvent indiquer une redondance de variables.
- Utile pour la sÃ©lection des variables dans les modÃ¨les prÃ©dictifs.

--- FEATURE ENGINEERING ---
âœ… Nouvelles variables crÃ©Ã©es :
  age_group  duration_min  total_contacts
0    Senior      4.350000               1
1    Adulte      2.516667               1
2    Adulte      1.266667               1
3    Senior      1.533333               1
4    Adulte      3.300000               1

ğŸ“Œ InterprÃ©tation des nouvelles variables :
- age_group : segmentation client plus claire.
- duration_min : plus interprÃ©table que les secondes.
- total_contacts : estimation de la pression commerciale sur le client.

### RÃ©partition par Ã¢ge
![RÃ©partition par groupe d'Ã¢ge](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/R%C3%A9partition%20par%20groupe%20d'%C3%A2ge.png?raw=true)

ğŸ“Œ InterprÃ©tation : Les adultes dominent le portefeuille clients.

### DurÃ©e (minutes)
![Distribution de la durÃ©e de contact](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20de%20la%20dur%C3%A9e%20de%20contact.png?raw=true)

ğŸ“Œ InterprÃ©tation : Les appels courts dominent â€” peu dâ€™appels longs trÃ¨s influents.

### Total contacts
![Distribution du nobre total de contacts](https://github.com/elamraouiabir6963encg-rgb/Projet-Dataset-Machine-learning/blob/main/Image/Distribution%20du%20nombre%20total%20de%20contacts.png?raw=true)

ğŸ“Œ InterprÃ©tation : La majoritÃ© des clients est contactÃ©e peu de fois, signe de ciblage sÃ©lectif.

---

# 6. INTERPRÃ‰TATION GÃ‰NÃ‰RALE

| Point               | Conclusion             |
| ------------------- | ---------------------- |
| Dataset             | fiable                 |
| Outliers            | nombreux               |
| CorrÃ©lation         | faible sauf `duration` |
| Feature engineering | pertinent              |
| ProblÃ¨me potentiel  | fuite de donnÃ©es       |

---

# 7. CONCLUSION

---

## Limites

* valeurs manquantes
* dÃ©sÃ©quilibre de classes
* variable biaisante `duration`
* absence de normalisation
* pas de modÃ¨le ML construit

---

## Pistes dâ€™amÃ©lioration

* Imputation intelligente
* Encodage catÃ©goriel
* Standardisation
* SÃ©lection de variables
* Validation croisÃ©e
* ModÃ©lisation ML (Logistic, Random Forest, XGBoost)

---

âœ… **Analyse exploratoire finalisÃ©e avec succÃ¨s.**

